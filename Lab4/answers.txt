How many cores will simple.cu use, max, as written? How many SMs?
    - 16 threads in 1 SM. (Grid contains one Block of size <16, 1>)


Is the calculated square root identical to what the CPU calculates? Should we assume that this is always the case?
    - As far as we can see yes, we can however not assume that this is true since GPU:s have the capability to work with half floats, giving less precision than the full counterparts.

How do you calculate the index in the array, using 2-dimensional blocks?
    int index_x = blockIdx.x * blockDim.x + threadIdx.x;
    int stride_x = blockDim.x * gridDim.x;
    int index_y = blockIdx.y * blockDim.y + threadIdx.y;
    int stride_y = blockDim.y * gridDim.y;

What happens if you use too many threads per block?
    - Cuda error: invalid configuration argument

At what data size is the GPU faster than the CPU?
    - At around N = 100 we start seeing the GPU pull ahead of the CPU

What block size seems like a good choice? Compared to what?
    - We found that a block size of 16x16 is the fastest out of the ones we tried (8x8, 16x16, 32x32)

Write down your data size, block size and timing data for the best GPU performance you can get.
    - N = 8192
    - 512x512 blocks with 16x16 threads per block
    =
    GPU Kernel executed in 22.839487 milliseconds
    CPU function executed in 1880.901978 milliseconds


What were the main changes in order to make the Mandelbrot run in CUDA?
    - Specify what functions/variables were to be run on the device using __device__ or __global__ depending on caller
    - Unwind the nested loop in the computeFractal function
    - Allocate/De-allocate space on the GPU

How many blocks and threads did you use?
    - 16x16 threads per block and gImageWidth/threadsPerBlock.x by gImageHeight/threadsPerBlock.y blocks.

When you use the Complex class, what modifier did you have to use on the methods?
    - We used __device__ since the functions would only ever be called from the device.

What performance did you get? How does that compare to the CPU solution?
    - The GPU-performance absolutely dumpsters the CPU-performance. CPU lags at the default number of iterations while we can spam the + button and not experience any slowdown on the GPU.

What performance did you get with float vs double precision?
    - Timing the computeFractal function we found the single & double precision prefomance to differ by 10x in favor of float.

In Lab 1, load balancing was an important issue. Is that an issue here? Why/why not?
    - No. CUDA seems to do some form of "load balancing" for us when we segment the image into blocks with 16x16 threads.